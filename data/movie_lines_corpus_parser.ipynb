{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movie_lines_corpus_parser",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5cLBG3DjTgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "!pip install tensorflow-datasets==1.2.0\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import re\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pstR6Defjg_k",
        "colab_type": "code",
        "outputId": "639c4085-b0be-4f31-b78f-b1edc5184d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'cornell_movie_dialogs.zip',\n",
        "    origin=\n",
        "    'http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_dataset = os.path.join(\n",
        "    os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\")\n",
        "\n",
        "path_to_movie_lines = os.path.join(path_to_dataset, 'movie_lines.txt')\n",
        "path_to_movie_conversations = os.path.join(path_to_dataset,\n",
        "                                           'movie_conversations.txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "9920512/9916637 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8kv0FrzjjE7",
        "colab_type": "code",
        "outputId": "3d30a655-48e5-4734-d198-8516b1ff92a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Maximum number of samples to preprocess\n",
        "MAX_SAMPLES = 50000\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "  sentence = sentence.lower().strip()\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  # adding a start and an end token to the sentence\n",
        "  return sentence\n",
        "\n",
        "\n",
        "def load_conversations():\n",
        "  # dictionary of line id to text\n",
        "  id2line = {}\n",
        "  with open(path_to_movie_lines, errors='ignore') as file:\n",
        "    lines = file.readlines()\n",
        "  for line in lines:\n",
        "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
        "    id2line[parts[0]] = parts[4]\n",
        "\n",
        "  inputs, outputs = [], []\n",
        "  with open(path_to_movie_conversations, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "  for line in lines:\n",
        "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
        "    # get conversation in a list of line ID\n",
        "    conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
        "    for i in range(len(conversation) - 1):\n",
        "      inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
        "      outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
        "  return inputs, outputs\n",
        "\n",
        "\n",
        "questions, answers = load_conversations()\n",
        "print(len(questions), 'questions and', len(answers), 'answers...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "221616 questions and 221616 answers...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeHCCL2Xj0oQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conversations = []\n",
        "\n",
        "for i in range(len(questions)):\n",
        "  conversations.append({'speaker': 'Q', 'msg': questions[i]})\n",
        "  conversations.append({'speaker': 'A', 'msg': answers[i]})\n",
        "\n",
        "\n",
        "with open('movie_conversations.json', 'w') as json_file:\n",
        "\tjson.dump({'conversations': [conversations]}, json_file)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}