{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ0YjJuNasmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from transformer import transformer\n",
        "from data_preprocessor import filter_line, build_word_matrix_row, load_data, load_movie_data\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pgwwBYXavms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\tdef __init__(self, d_model, warmup_steps = 4000):\n",
        "\t\tsuper(CustomSchedule, self).__init__()\n",
        "\n",
        "\t\tself.d_model = d_model\n",
        "\t\tself.d_model = tf.cast(self.d_model, dtype = tf.float32)\n",
        "\t\tself.warmup_steps = warmup_steps\n",
        "\n",
        "\tdef __call__(self, step):\n",
        "\t\targ1 = tf.math.rsqrt(step)\n",
        "\t\targ2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "\t\treturn tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "def loss_function(y_true, y_pred):\n",
        "\ty_true = tf.reshape(y_true, shape = (-1, limits['max_a_len'] + 1))\n",
        "\tloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')(y_true, y_pred)\n",
        "\tmask = tf.cast(tf.not_equal(y_true, 0), dtype = tf.float32)\n",
        "\tloss = tf.multiply(loss, mask)\n",
        "\n",
        "\treturn tf.reduce_mean(loss)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "\ty_true = tf.reshape(y_true, shape = (-1, limits['max_a_len'] + 1))\n",
        "\treturn tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "def evaluate(sentence):\n",
        "\tsentence = filter_line(sentence)\n",
        "\tsentence = tf.expand_dims(build_word_matrix_row(sentence, metadata['word_to_idx'], limits['max_q_len']), axis = 0)\n",
        "\toutput = tf.expand_dims(start_token, 0)\n",
        "\n",
        "\tfor i in range(limits['max_a_len']):\n",
        "\t\tpredictions = model(inputs = [sentence, output], training = False)\n",
        "\n",
        "\t\tpredictions = predictions[:, -1:, :]\n",
        "\t\tpredicted_id = tf.cast(tf.argmax(predictions, axis = -1), dtype = tf.int32)\n",
        "\n",
        "\t\tif tf.equal(predicted_id, end_token[0]):\n",
        "\t\t\tbreak\n",
        "\n",
        "\t\toutput = tf.concat([output, predicted_id], axis = -1)\n",
        "\n",
        "\treturn tf.squeeze(output, axis = 0)\n",
        "\n",
        "def predict(sentence):\n",
        "\tprediction = evaluate(sentence)\n",
        "\tpredicted_sentence = ' '.join([metadata['idx_to_word'][i] for i in prediction[1:]])\n",
        "\treturn predicted_sentence\n",
        "\n",
        "def train_model(dataset, epochs = 10):\n",
        "\tcheckpoint_path = 'training_checkpoints/cp.ckpt'\n",
        "\tcheckpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\tcp_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path, save_weights_only = True, verbose = 1)\n",
        "\n",
        "\tmodel.fit(dataset, epochs = epochs, callbacks = [cp_callback])\n",
        "\n",
        "def load_model():\n",
        "\tmodel.load_weights('training_checkpoints/cp.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dF7DJuhawry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metadata, questions, answers = load_data(path = 'metadata/')\n",
        "# metadata, questions, answers = load_movie_data(path = '')\n",
        "\n",
        "batch_size = 64\n",
        "buffer_size = 20000\n",
        "vocab_size = 6000\n",
        "start_token = [vocab_size]\n",
        "end_token = [vocab_size + 1]\n",
        "vocab_size += 2\n",
        "limits = metadata['limits']\n",
        "\n",
        "num_layers = 2\n",
        "d_model = 256\n",
        "num_heads = 8\n",
        "units = 512\n",
        "dropout = 0.1\n",
        "# epochs = 50\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "\t{\n",
        "\t\t'inputs': questions,\n",
        "\t\t'dec_inputs': answers[:, :-1]\n",
        "\t},\n",
        "\t{\n",
        "\t\t'outputs': answers[:, 1:]\n",
        "\t}\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(buffer_size)\n",
        "dataset = dataset.batch(batch_size)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model = transformer(vocab_size = vocab_size + 2, num_layers = num_layers, units = units, d_model = d_model, num_heads = num_heads, dropout = dropout)\n",
        "\n",
        "learning_rate = CustomSchedule(d_model = d_model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1 = 0.9, beta_2 = 0.98, epsilon = 1e-9)\n",
        "\n",
        "model.compile(optimizer = optimizer, loss = loss_function, metrics = [accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEhERhjdw7C7",
        "colab_type": "code",
        "outputId": "a9a647fd-fa20-489d-d8de-f2e933b50f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_model(dataset, epochs = 50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 1.3195 - accuracy: 0.0179\n",
            "Epoch 00001: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 1.3195 - accuracy: 0.0179\n",
            "Epoch 2/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 1.0431 - accuracy: 0.0247\n",
            "Epoch 00002: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 1.0431 - accuracy: 0.0247\n",
            "Epoch 3/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.9584 - accuracy: 0.0310\n",
            "Epoch 00003: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.9584 - accuracy: 0.0310\n",
            "Epoch 4/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.9089 - accuracy: 0.0335\n",
            "Epoch 00004: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.9089 - accuracy: 0.0335\n",
            "Epoch 5/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.8705 - accuracy: 0.0358\n",
            "Epoch 00005: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 76ms/step - loss: 0.8705 - accuracy: 0.0358\n",
            "Epoch 6/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.8358 - accuracy: 0.0380\n",
            "Epoch 00006: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.8358 - accuracy: 0.0380\n",
            "Epoch 7/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.8018 - accuracy: 0.0403\n",
            "Epoch 00007: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 76ms/step - loss: 0.8018 - accuracy: 0.0403\n",
            "Epoch 8/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.7676 - accuracy: 0.0429\n",
            "Epoch 00008: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 76ms/step - loss: 0.7676 - accuracy: 0.0429\n",
            "Epoch 9/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.7307 - accuracy: 0.0459\n",
            "Epoch 00009: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.7307 - accuracy: 0.0459\n",
            "Epoch 10/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.0491\n",
            "Epoch 00010: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.6928 - accuracy: 0.0491\n",
            "Epoch 11/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.6530 - accuracy: 0.0529\n",
            "Epoch 00011: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 76ms/step - loss: 0.6530 - accuracy: 0.0529\n",
            "Epoch 12/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.6146 - accuracy: 0.0568\n",
            "Epoch 00012: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.6146 - accuracy: 0.0568\n",
            "Epoch 13/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.5731 - accuracy: 0.0619\n",
            "Epoch 00013: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.5731 - accuracy: 0.0619\n",
            "Epoch 14/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.5205 - accuracy: 0.0686\n",
            "Epoch 00014: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.5205 - accuracy: 0.0686\n",
            "Epoch 15/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.4712 - accuracy: 0.0756\n",
            "Epoch 00015: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 76ms/step - loss: 0.4712 - accuracy: 0.0756\n",
            "Epoch 16/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.4274 - accuracy: 0.0830\n",
            "Epoch 00016: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 76ms/step - loss: 0.4274 - accuracy: 0.0830\n",
            "Epoch 17/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.0896\n",
            "Epoch 00017: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 76ms/step - loss: 0.3876 - accuracy: 0.0896\n",
            "Epoch 18/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.3525 - accuracy: 0.0960\n",
            "Epoch 00018: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 76ms/step - loss: 0.3525 - accuracy: 0.0960\n",
            "Epoch 19/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.1013\n",
            "Epoch 00019: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 26s 77ms/step - loss: 0.3232 - accuracy: 0.1013\n",
            "Epoch 20/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.2970 - accuracy: 0.1063\n",
            "Epoch 00020: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 26s 78ms/step - loss: 0.2970 - accuracy: 0.1063\n",
            "Epoch 21/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.2747 - accuracy: 0.1105\n",
            "Epoch 00021: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 77ms/step - loss: 0.2747 - accuracy: 0.1105\n",
            "Epoch 22/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.2543 - accuracy: 0.1149\n",
            "Epoch 00022: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 76ms/step - loss: 0.2543 - accuracy: 0.1149\n",
            "Epoch 23/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.2381 - accuracy: 0.1181\n",
            "Epoch 00023: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 26s 77ms/step - loss: 0.2381 - accuracy: 0.1181\n",
            "Epoch 24/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.1212\n",
            "Epoch 00024: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 26s 77ms/step - loss: 0.2233 - accuracy: 0.1212\n",
            "Epoch 25/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.2089 - accuracy: 0.1246\n",
            "Epoch 00025: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 26s 77ms/step - loss: 0.2089 - accuracy: 0.1246\n",
            "Epoch 26/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.1973 - accuracy: 0.1271\n",
            "Epoch 00026: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 26s 77ms/step - loss: 0.1973 - accuracy: 0.1271\n",
            "Epoch 27/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.1871 - accuracy: 0.1293\n",
            "Epoch 00027: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 26s 77ms/step - loss: 0.1871 - accuracy: 0.1293\n",
            "Epoch 28/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.1776 - accuracy: 0.1316\n",
            "Epoch 00028: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 26s 77ms/step - loss: 0.1776 - accuracy: 0.1316\n",
            "Epoch 29/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.1688 - accuracy: 0.1337\n",
            "Epoch 00029: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 26s 77ms/step - loss: 0.1688 - accuracy: 0.1337\n",
            "Epoch 30/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.1599 - accuracy: 0.1359\n",
            "Epoch 00030: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 26s 77ms/step - loss: 0.1599 - accuracy: 0.1359\n",
            "Epoch 31/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.1528 - accuracy: 0.1375\n",
            "Epoch 00031: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 26s 77ms/step - loss: 0.1528 - accuracy: 0.1375\n",
            "Epoch 32/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.1453 - accuracy: 0.1394\n",
            "Epoch 00032: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 26s 77ms/step - loss: 0.1453 - accuracy: 0.1394\n",
            "Epoch 33/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.1401 - accuracy: 0.1406\n",
            "Epoch 00033: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 76ms/step - loss: 0.1401 - accuracy: 0.1406\n",
            "Epoch 34/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.1418\n",
            "Epoch 00034: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 76ms/step - loss: 0.1347 - accuracy: 0.1418\n",
            "Epoch 35/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.1291 - accuracy: 0.1433\n",
            "Epoch 00035: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 76ms/step - loss: 0.1291 - accuracy: 0.1433\n",
            "Epoch 36/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.1244 - accuracy: 0.1443\n",
            "Epoch 00036: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 76ms/step - loss: 0.1244 - accuracy: 0.1443\n",
            "Epoch 37/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.1198 - accuracy: 0.1456\n",
            "Epoch 00037: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.1198 - accuracy: 0.1456\n",
            "Epoch 38/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.1163 - accuracy: 0.1464\n",
            "Epoch 00038: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.1163 - accuracy: 0.1464\n",
            "Epoch 39/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.1117 - accuracy: 0.1477\n",
            "Epoch 00039: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.1117 - accuracy: 0.1477\n",
            "Epoch 40/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.1076 - accuracy: 0.1488\n",
            "Epoch 00040: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.1076 - accuracy: 0.1488\n",
            "Epoch 41/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.1495\n",
            "Epoch 00041: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.1041 - accuracy: 0.1495\n",
            "Epoch 42/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.1504\n",
            "Epoch 00042: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.1010 - accuracy: 0.1504\n",
            "Epoch 43/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.1511\n",
            "Epoch 00043: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.0982 - accuracy: 0.1511\n",
            "Epoch 44/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.1519\n",
            "Epoch 00044: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.0950 - accuracy: 0.1519\n",
            "Epoch 45/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.0924 - accuracy: 0.1528\n",
            "Epoch 00045: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.0924 - accuracy: 0.1528\n",
            "Epoch 46/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.1535\n",
            "Epoch 00046: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.0899 - accuracy: 0.1535\n",
            "Epoch 47/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.1540\n",
            "Epoch 00047: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 76ms/step - loss: 0.0873 - accuracy: 0.1540\n",
            "Epoch 48/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 0.1546\n",
            "Epoch 00048: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.0849 - accuracy: 0.1546\n",
            "Epoch 49/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.1551\n",
            "Epoch 00049: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.0830 - accuracy: 0.1551\n",
            "Epoch 50/50\n",
            "333/333 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.1556\n",
            "Epoch 00050: saving model to training_checkpoints/cp.ckpt\n",
            "333/333 [==============================] - 25s 75ms/step - loss: 0.0811 - accuracy: 0.1556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcWDwlnjkJ-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emUNWATTa3W0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "while True:\n",
        "  question = input('Me: ')\n",
        "  answer = predict(question)\n",
        "  print('Trevan:', answer)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}